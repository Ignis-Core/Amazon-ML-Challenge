{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTMed1LnOVli",
        "outputId": "f512c696-85dc-4dee-99de-76b24716af36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Libraries loaded successfully!\n",
            "‚úÖ Libraries loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# STEP 1: Setup & Imports\n",
        "# =======================\n",
        "\n",
        "!pip install lightgbm --quiet\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import lightgbm as lgb\n",
        "from scipy import sparse\n",
        "import time\n",
        "\n",
        "print(\"‚úÖ Libraries loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0) Install (only if needed) and imports\n",
        "# ------------------------------------------------\n",
        "!pip install -q lightgbm tqdm scikit-learn joblib\n",
        "\n",
        "import os, time, re, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from scipy import sparse\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import KFold\n",
        "import lightgbm as lgb\n",
        "import joblib\n",
        "\n",
        "# 1) Config & Paths (edit your dataset path here)\n",
        "# ------------------------------------------------\n",
        "DATA_DIR = \"/content/drive/MyDrive/dataset\"   # <-- change if needed\n",
        "TRAIN_F = os.path.join(DATA_DIR, \"train.csv\")\n",
        "TEST_F  = os.path.join(DATA_DIR, \"test.csv\")\n",
        "OUTPUT_PRED = \"test_out.csv\"\n",
        "ARTIFACTS_F = \"model_artifacts.joblib\"\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "N_FOLDS = 5               # 5-fold CV as requested\n",
        "TFIDF_MAX_WORD = 10000    # increased TF-IDF\n",
        "TFIDF_MAX_CHAR = 3000\n",
        "CHAR_NGRAM = (2,4)\n",
        "WORD_NGRAM = (1,2)\n",
        "\n",
        "LGB_NUM_BOOST_ROUND = 1000\n",
        "EARLY_STOPPING_ROUNDS = 50\n",
        "\n",
        "# Ensemble / tuning: two light configs (fast and robust)\n",
        "LGB_CONFIGS = [\n",
        "    {\"name\":\"fast\",\"num_leaves\":31,\"learning_rate\":0.05,\"n_jobs\":2},\n",
        "    {\"name\":\"robust\",\"num_leaves\":64,\"learning_rate\":0.03,\"n_jobs\":2}\n",
        "]\n",
        "\n",
        "# Safety note displayed at runtime\n",
        "print(\"CONFIG: TFIDF_WORD =\", TFIDF_MAX_WORD, \", TFIDF_CHAR =\", TFIDF_MAX_CHAR)\n",
        "print(\"CONFIG: 5-fold CV, ensemble of\", len(LGB_CONFIGS), \"LightGBM models\")\n",
        "print()\n",
        "DATA_DIR = \"/content/drive/MyDrive/amazonimages\"  # <-- change this\n",
        "TRAIN_F = os.path.join(DATA_DIR, \"train.csv\")\n",
        "TEST_F  = os.path.join(DATA_DIR, \"test.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hs5QmdzSQOlT",
        "outputId": "9b2f1671-8e23-4c3c-d033-95e4a7ec85a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFIG: TFIDF_WORD = 10000 , TFIDF_CHAR = 3000\n",
            "CONFIG: 5-fold CV, ensemble of 2 LightGBM models\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Mount Drive (if using Colab) - run once\n",
        "# ------------------------------------------------\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "except Exception:\n",
        "    # Not in Colab or already mounted\n",
        "    pass\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOSPYLAGQVr_",
        "outputId": "915baded-5ad8-49db-c304-d721ab9b9024"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Utility functions\n",
        "# ------------------------------------------------\n",
        "def timer(start, text=\"Elapsed\"):\n",
        "    return f\"{text}: {time.time()-start:.1f}s\"\n",
        "\n",
        "def smape(y_true, y_pred):\n",
        "    y_true = np.array(y_true, dtype=np.float64)\n",
        "    y_pred = np.array(y_pred, dtype=np.float64)\n",
        "    denom = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
        "    denom[denom == 0] = 1e-8\n",
        "    return np.mean(np.abs(y_true - y_pred) / denom) * 100.0\n",
        "\n",
        "def safe_text(x):\n",
        "    if pd.isna(x):\n",
        "        return \"\"\n",
        "    x = str(x).lower()\n",
        "    x = re.sub(r\"http\\S+|www\\S+\", \"\", x)\n",
        "    x = re.sub(r\"[^a-z0-9\\s]\", \" \", x)\n",
        "    x = re.sub(r\"\\s+\", \" \", x).strip()\n",
        "    return x\n",
        "\n",
        "# Step 3 is very fast; negligible time (~0.1s)\n"
      ],
      "metadata": {
        "id": "hMg_sJ8vQu0o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Load data\n",
        "# ------------------------------------------------\n",
        "# Check what files are present in the folder\n",
        "!ls /content/drive/MyDrive/amazonimages   # <-- should list train.csv & test.csv\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# Update paths to your actual CSV files\n",
        "TRAIN_F = \"/content/drive/MyDrive/amazonimages/train.csv\"\n",
        "TEST_F  = \"/content/drive/MyDrive/amazonimages/test.csv\"\n",
        "\n",
        "print(\"Loading data from:\", TRAIN_F, TEST_F)\n",
        "train = pd.read_csv(TRAIN_F)\n",
        "test = pd.read_csv(TEST_F)\n",
        "print(\"Loaded shapes -> train:\", train.shape, \" test:\", test.shape)\n",
        "print(\"Crash risk: ‚úÖ Very low (CSV load only).\")\n",
        "\n",
        "t1 = time.time()\n",
        "print(f\"Step 4 time: {t1-t0:.1f}s\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eD5MsxDuQ299",
        "outputId": "7fb214f0-b375-484b-af88-1e128db865f6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test.csv  train.csv\n",
            "Loading data from: /content/drive/MyDrive/amazonimages/train.csv /content/drive/MyDrive/amazonimages/test.csv\n",
            "Loaded shapes -> train: (75000, 4)  test: (75000, 3)\n",
            "Crash risk: ‚úÖ Very low (CSV load only).\n",
            "Step 4 time: 3.5s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) Basic cleaning & tuned text fields\n",
        "# ------------------------------------------------\n",
        "t0 = time.time()\n",
        "train['clean_text'] = train['catalog_content'].apply(safe_text)\n",
        "test['clean_text']  = test['catalog_content'].apply(safe_text)\n",
        "print(\"Cleaned text fields.\")\n",
        "\n",
        "t1 = time.time()\n",
        "print(f\"Step 5 time: {t1-t0:.1f}s\")\n",
        "print(\"Crash risk: ‚úÖ Very low.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqC_LHr2Sx73",
        "outputId": "9e1a8629-25a1-423d-ba9d-8e49cc341b2a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned text fields.\n",
            "Step 5 time: 16.9s\n",
            "Crash risk: ‚úÖ Very low.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Step 6: Numeric/text features (vectorized)\n",
        "# =========================\n",
        "t0 = time.time()\n",
        "\n",
        "def extract_text_numeric_fast(df, src_col='catalog_content'):\n",
        "    s = df[src_col].fillna(\"\").astype(str)\n",
        "\n",
        "    # Basic counts\n",
        "    len_text = s.str.len().astype(np.int32)\n",
        "    num_words = s.str.count(r'\\S+').astype(np.int32)          # count words fast\n",
        "    num_digits = s.str.count(r'\\d').astype(np.int32)\n",
        "    num_commas = s.str.count(',').astype(np.int32)\n",
        "    # Use non-capturing group (?:...) to avoid warning\n",
        "    has_unit = s.str.contains(r'\\b(?:ml|g|kg|l|oz|pack|pcs|pair)\\b', flags=re.IGNORECASE).astype(np.int8)\n",
        "\n",
        "    # Ratios (safe division)\n",
        "    digits_per_word = (num_digits / num_words.replace(0,1)).astype(np.float32)\n",
        "    chars_per_word  = (len_text / num_words.replace(0,1)).astype(np.float32)\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        'len_text': len_text,\n",
        "        'num_words': num_words,\n",
        "        'num_digits': num_digits,\n",
        "        'num_commas': num_commas,\n",
        "        'has_unit': has_unit,\n",
        "        'digits_per_word': digits_per_word,\n",
        "        'chars_per_word': chars_per_word\n",
        "    })\n",
        "\n",
        "# Apply to train and test\n",
        "num_feat_train = extract_text_numeric_fast(train, 'catalog_content')\n",
        "num_feat_test  = extract_text_numeric_fast(test, 'catalog_content')\n",
        "\n",
        "print(\"Numeric text features shape:\", num_feat_train.shape)\n",
        "print(timer(t0, \"Step 6 time\"))\n",
        "print(\"Crash risk: ‚úÖ Very low (vectorized, CPU-friendly).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtyOwTchAFM-",
        "outputId": "16c61ac8-9660-4a48-ba82-be782b2cd71c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numeric text features shape: (75000, 7)\n",
            "Step 6 time: 15.7s\n",
            "Crash risk: ‚úÖ Very low (vectorized, CPU-friendly).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "\n",
        "def extract_image_url_features_fast(df, col='image_link'):\n",
        "    # Ensure Series\n",
        "    s = df[col] if isinstance(df[col], pd.Series) else pd.Series(df[col])\n",
        "    s = s.fillna('').astype(str)\n",
        "\n",
        "    # Basic URL patterns\n",
        "    img_len = s.str.len().astype(np.int32)\n",
        "    img_https = s.str.startswith('https').astype(np.int8)\n",
        "    img_num_digits = s.str.count(r'\\d').astype(np.int32)\n",
        "    img_num_letters = s.str.count(r'[A-Za-z]').astype(np.int32)\n",
        "    img_num_slash = s.str.count('/').astype(np.int32)\n",
        "    img_num_dash = s.str.count('-').astype(np.int32)\n",
        "    img_jpg = s.str.lower().str.contains('.jpg').astype(np.int8)\n",
        "    img_png = s.str.lower().str.contains('.png').astype(np.int8)\n",
        "\n",
        "    # Extract filename part\n",
        "    file_part = s.str.extract(r'/([^/]+\\.(?:jpg|png))', expand=False)\n",
        "    file_part = file_part.fillna('')\n",
        "    file_len = file_part.str.len().astype(np.int32)\n",
        "    file_digits = file_part.str.count(r'\\d').astype(np.int32)\n",
        "    file_letters = file_part.str.count(r'[A-Za-z]').astype(np.int32)\n",
        "\n",
        "    # Last 2 chars ASCII sum\n",
        "    last2 = file_part.str[-2:].fillna('00')\n",
        "    last2_code = (last2.str[0].apply(ord) + last2.str[1].apply(ord)).astype(np.int32)\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        'img_len': img_len,\n",
        "        'img_https': img_https,\n",
        "        'img_num_digits': img_num_digits,\n",
        "        'img_num_letters': img_num_letters,\n",
        "        'img_num_slash': img_num_slash,\n",
        "        'img_num_dash': img_num_dash,\n",
        "        'img_jpg': img_jpg,\n",
        "        'img_png': img_png,\n",
        "        'img_file_len': file_len,\n",
        "        'img_file_digits': file_digits,\n",
        "        'img_file_letters': file_letters,\n",
        "        'img_last2_code': last2_code\n",
        "    })\n",
        "\n",
        "# Apply to train and test\n",
        "img_feat_train = extract_image_url_features_fast(train)\n",
        "img_feat_test  = extract_image_url_features_fast(test)\n",
        "\n",
        "print(\"Image URL features shape:\", img_feat_train.shape)\n",
        "print(timer(t0, \"Step 7 time\"))\n",
        "print(\"Crash risk: ‚úÖ Very low (vectorized, CPU-friendly).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBRsd5XGAnyj",
        "outputId": "3a7fdfa9-5e23-43f8-d9ab-cc42268142bb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image URL features shape: (75000, 12)\n",
            "Step 7 time: 4.1s\n",
            "Crash risk: ‚úÖ Very low (vectorized, CPU-friendly).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "\n",
        "t0 = time.time()\n",
        "print(\"Using HashingVectorizer for CPU-friendly TF-IDF...\")\n",
        "\n",
        "# Word-level\n",
        "hv_word = HashingVectorizer(\n",
        "    n_features=10000,   # same as TF-IDF max_features\n",
        "    ngram_range=(1,2),\n",
        "    alternate_sign=False,  # positive values only\n",
        "    norm='l2',\n",
        "    dtype=np.float32\n",
        ")\n",
        "\n",
        "# Char-level\n",
        "hv_char = HashingVectorizer(\n",
        "    n_features=3000,\n",
        "    analyzer='char',\n",
        "    ngram_range=(2,4),\n",
        "    alternate_sign=False,\n",
        "    norm='l2',\n",
        "    dtype=np.float32\n",
        ")\n",
        "\n",
        "# Transform train + test\n",
        "Xw_train = hv_word.transform(train['clean_text'])\n",
        "Xw_test  = hv_word.transform(test['clean_text'])\n",
        "Xc_train = hv_char.transform(train['clean_text'])\n",
        "Xc_test  = hv_char.transform(test['clean_text'])\n",
        "\n",
        "print(\"HashingVectorizer shapes -> word:\", Xw_train.shape, \" char:\", Xc_train.shape)\n",
        "print(timer(t0, \"Step 8 time\"))\n",
        "print(\"Crash risk: ‚úÖ Very low (fast + memory-efficient)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOiUNh0eAz6C",
        "outputId": "c1e46248-bfea-450c-e266-ec649fc40274"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using HashingVectorizer for CPU-friendly TF-IDF...\n",
            "HashingVectorizer shapes -> word: (75000, 10000)  char: (75000, 3000)\n",
            "Step 8 time: 242.9s\n",
            "Crash risk: ‚úÖ Very low (fast + memory-efficient)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "import gc\n",
        "import time\n",
        "\n",
        "t0 = time.time()\n",
        "print(\"Step 9: Stacking all features into sparse matrix...\")\n",
        "\n",
        "# -----------------------------\n",
        "# Numeric features ‚Üí sparse\n",
        "# -----------------------------\n",
        "num_train_sp = csr_matrix(num_feat_train.values.astype(np.float32))\n",
        "num_test_sp  = csr_matrix(num_feat_test.values.astype(np.float32))\n",
        "\n",
        "# -----------------------------\n",
        "# Image URL features ‚Üí sparse\n",
        "# -----------------------------\n",
        "img_train_sp = csr_matrix(img_feat_train.values.astype(np.float32))\n",
        "img_test_sp  = csr_matrix(img_feat_test.values.astype(np.float32))\n",
        "\n",
        "# -----------------------------\n",
        "# Stack: TF-IDF + numeric + image\n",
        "# -----------------------------\n",
        "X_train = hstack([Xw_train, Xc_train, num_train_sp, img_train_sp], format='csr')\n",
        "X_test  = hstack([Xw_test, Xc_test, num_test_sp, img_test_sp], format='csr')\n",
        "\n",
        "print(\"Combined feature shapes -> X_train:\", X_train.shape, \" X_test:\", X_test.shape)\n",
        "print(timer(t0, \"Step 9 time\"))\n",
        "\n",
        "# -----------------------------\n",
        "# Clean up to free memory\n",
        "# -----------------------------\n",
        "del num_train_sp, num_test_sp, img_train_sp, img_test_sp\n",
        "gc.collect()\n",
        "\n",
        "print(\"Crash risk: ‚úÖ Very low (sparse, CPU-friendly, ready for training)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i76Kn39_F0Ga",
        "outputId": "826897a4-7bf9-41cd-8662-fd712ee35db6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 9: Stacking all features into sparse matrix...\n",
            "Combined feature shapes -> X_train: (75000, 13019)  X_test: (75000, 13019)\n",
            "Step 9 time: 3.2s\n",
            "Crash risk: ‚úÖ Very low (sparse, CPU-friendly, ready for training)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "t0 = time.time()\n",
        "print(\"Step 10: Preparing target variable...\")\n",
        "\n",
        "# Fill missing prices and ensure float32\n",
        "y = train['price'].fillna(0).values.astype(np.float32)\n",
        "\n",
        "# Clip negative values to 0 (just in case)\n",
        "y = np.maximum(y, 0.0)\n",
        "\n",
        "# Apply log1p transform for skew reduction\n",
        "y_log = np.log1p(y)\n",
        "\n",
        "print(\"Target prepared: original shape =\", y.shape)\n",
        "print(\"Sample log1p values:\", y_log[:5])\n",
        "print(timer(t0, \"Step 10 time\"))\n",
        "print(\"Crash risk: ‚úÖ Very low\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RA1mNyZuF7YZ",
        "outputId": "c5898141-0825-42e5-acde-25ea4012ee94"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 10: Preparing target variable...\n",
            "Target prepared: original shape = (75000,)\n",
            "Sample log1p values: [1.773256  2.6475923 1.088562  3.4448953 4.2119794]\n",
            "Step 10 time: 0.0s\n",
            "Crash risk: ‚úÖ Very low\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from lightgbm import early_stopping, log_evaluation\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "import gc\n",
        "import time\n",
        "\n",
        "t0_total = time.time()\n",
        "N_FOLDS = 5\n",
        "RANDOM_STATE = 42\n",
        "TEST_BATCH_SIZE = 10000  # safer for weaker CPUs\n",
        "\n",
        "# Ensemble configs\n",
        "LGB_CONFIGS = [\n",
        "    {\"name\": \"fast\", \"num_leaves\": 31, \"learning_rate\": 0.05, \"n_jobs\": 2},\n",
        "    {\"name\": \"robust\", \"num_leaves\": 64, \"learning_rate\": 0.03, \"n_jobs\": 2}\n",
        "]\n",
        "\n",
        "# Containers for OOF and test predictions\n",
        "oof_preds_all = np.zeros(len(train), dtype=np.float64)\n",
        "test_preds_all = np.zeros(X_test.shape[0], dtype=np.float64)\n",
        "\n",
        "kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "# SMAPE function\n",
        "def smape(y_true, y_pred):\n",
        "    denom = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
        "    denom[denom == 0] = 1e-8\n",
        "    return np.mean(np.abs(y_true - y_pred) / denom) * 100.0\n",
        "\n",
        "# -----------------------------\n",
        "# Start CPU-safe ensemble training\n",
        "# -----------------------------\n",
        "for cfg_idx, cfg in enumerate(LGB_CONFIGS, 1):\n",
        "    print(f\"\\n=== Config {cfg_idx}/{len(LGB_CONFIGS)}: {cfg['name']} ===\")\n",
        "    oof_preds = np.zeros(len(train), dtype=np.float64)\n",
        "    test_preds = np.zeros(X_test.shape[0], dtype=np.float64)\n",
        "\n",
        "    for fold, (train_idx, valid_idx) in enumerate(kf.split(X_train), 1):\n",
        "        print(f\"\\n-- Fold {fold}/{N_FOLDS} --\")\n",
        "        t_fold = time.time()\n",
        "\n",
        "        # -----------------------------\n",
        "        # Train on current fold\n",
        "        # -----------------------------\n",
        "        X_tr, X_val = X_train[train_idx], X_train[valid_idx]\n",
        "        y_tr, y_val = y_log[train_idx], y_log[valid_idx]\n",
        "\n",
        "        lgb_params = {\n",
        "            \"objective\": \"regression\",\n",
        "            \"metric\": \"rmse\",\n",
        "            \"boosting_type\": \"gbdt\",\n",
        "            \"learning_rate\": cfg['learning_rate'],\n",
        "            \"num_leaves\": cfg['num_leaves'],\n",
        "            \"feature_fraction\": 0.8,\n",
        "            \"bagging_fraction\": 0.9,\n",
        "            \"bagging_freq\": 1,\n",
        "            \"verbose\": -1,\n",
        "            \"seed\": RANDOM_STATE,\n",
        "            \"n_jobs\": cfg['n_jobs']\n",
        "        }\n",
        "\n",
        "        dtrain = lgb.Dataset(X_tr, label=y_tr)\n",
        "        dvalid = lgb.Dataset(X_val, label=y_val)\n",
        "\n",
        "        # -----------------------------\n",
        "        # Early stopping callback\n",
        "        # -----------------------------\n",
        "        model = lgb.train(\n",
        "            lgb_params,\n",
        "            dtrain,\n",
        "            num_boost_round=1000,\n",
        "            valid_sets=[dtrain, dvalid],\n",
        "            valid_names=['train','valid'],\n",
        "            callbacks=[\n",
        "                early_stopping(stopping_rounds=50),\n",
        "                log_evaluation(period=100)  # prints progress every 100 rounds\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # -----------------------------\n",
        "        # Validation predictions\n",
        "        # -----------------------------\n",
        "        val_pred_log = model.predict(X_val, num_iteration=model.best_iteration)\n",
        "        oof_preds[valid_idx] = np.expm1(val_pred_log)\n",
        "\n",
        "        # -----------------------------\n",
        "        # Test predictions in chunks\n",
        "        # -----------------------------\n",
        "        test_pred_log = np.zeros(X_test.shape[0], dtype=np.float32)\n",
        "        for start in range(0, X_test.shape[0], TEST_BATCH_SIZE):\n",
        "            end = min(start + TEST_BATCH_SIZE, X_test.shape[0])\n",
        "            test_pred_log[start:end] = model.predict(X_test[start:end], num_iteration=model.best_iteration)\n",
        "        test_preds += np.expm1(test_pred_log)\n",
        "\n",
        "        print(f\"Fold {fold} done. Fold time: {time.time()-t_fold:.1f}s\")\n",
        "\n",
        "        # -----------------------------\n",
        "        # Free memory\n",
        "        # -----------------------------\n",
        "        del X_tr, X_val, y_tr, y_val, dtrain, dvalid, model, val_pred_log, test_pred_log\n",
        "        gc.collect()\n",
        "\n",
        "    # Average test predictions over folds\n",
        "    test_preds /= N_FOLDS\n",
        "\n",
        "    # Accumulate ensemble\n",
        "    oof_preds_all += oof_preds\n",
        "    test_preds_all += test_preds\n",
        "\n",
        "    # SMAPE for this config\n",
        "    config_smape = smape(y, oof_preds)\n",
        "    print(f\"Config '{cfg['name']}' OOF SMAPE: {config_smape:.4f}%\")\n",
        "\n",
        "# -----------------------------\n",
        "# Final ensemble average across configs\n",
        "# -----------------------------\n",
        "oof_preds_all /= len(LGB_CONFIGS)\n",
        "test_preds_all /= len(LGB_CONFIGS)\n",
        "\n",
        "final_smape = smape(y, oof_preds_all)\n",
        "print(\"\\nFinal ensemble OOF SMAPE: {:.4f}%\".format(final_smape))\n",
        "print(\"Step 11 total time: {:.1f}s (~{:.1f} min)\".format(time.time()-t0_total, (time.time()-t0_total)/60))\n",
        "\n",
        "# -----------------------------\n",
        "# Safety notes (comments only)\n",
        "# -----------------------------\n",
        "# 1) Keep TEST_BATCH_SIZE <= 15k (or 10k if RAM is low)\n",
        "# 2) Close other heavy programs while training\n",
        "# 3) Sparse matrices + float32 save memory\n",
        "# 4) 5-fold CV is a good tradeoff between accuracy and speed\n",
        "# 5) Expected OOF SMAPE with this setup: ~40‚Äì45%\n",
        "# 6) CPU-friendly: no step should crash your system\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bmZSBV0uH6lj",
        "outputId": "ef12da4d-22e2-4f7f-de46-4798c568cfb2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Config 1/2: fast ===\n",
            "\n",
            "-- Fold 1/5 --\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "[100]\ttrain's rmse: 0.714817\tvalid's rmse: 0.760125\n",
            "[200]\ttrain's rmse: 0.662427\tvalid's rmse: 0.734221\n",
            "[300]\ttrain's rmse: 0.627348\tvalid's rmse: 0.723591\n",
            "[400]\ttrain's rmse: 0.599106\tvalid's rmse: 0.717126\n",
            "[500]\ttrain's rmse: 0.574095\tvalid's rmse: 0.712499\n",
            "[600]\ttrain's rmse: 0.552088\tvalid's rmse: 0.709302\n",
            "[700]\ttrain's rmse: 0.53158\tvalid's rmse: 0.706656\n",
            "[800]\ttrain's rmse: 0.512998\tvalid's rmse: 0.704324\n",
            "[900]\ttrain's rmse: 0.495443\tvalid's rmse: 0.702808\n",
            "[1000]\ttrain's rmse: 0.479188\tvalid's rmse: 0.701475\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttrain's rmse: 0.479188\tvalid's rmse: 0.701475\n",
            "Fold 1 done. Fold time: 2624.0s\n",
            "\n",
            "-- Fold 2/5 --\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "[100]\ttrain's rmse: 0.718503\tvalid's rmse: 0.745107\n",
            "[200]\ttrain's rmse: 0.666453\tvalid's rmse: 0.718768\n",
            "[300]\ttrain's rmse: 0.630971\tvalid's rmse: 0.708521\n",
            "[400]\ttrain's rmse: 0.602497\tvalid's rmse: 0.701618\n",
            "[500]\ttrain's rmse: 0.577628\tvalid's rmse: 0.697803\n",
            "[600]\ttrain's rmse: 0.555384\tvalid's rmse: 0.694642\n",
            "[700]\ttrain's rmse: 0.534884\tvalid's rmse: 0.691956\n",
            "[800]\ttrain's rmse: 0.515522\tvalid's rmse: 0.689888\n",
            "[900]\ttrain's rmse: 0.497611\tvalid's rmse: 0.68842\n",
            "[1000]\ttrain's rmse: 0.481169\tvalid's rmse: 0.686741\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttrain's rmse: 0.481169\tvalid's rmse: 0.686741\n",
            "Fold 2 done. Fold time: 2612.4s\n",
            "\n",
            "-- Fold 3/5 --\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "[100]\ttrain's rmse: 0.718989\tvalid's rmse: 0.743315\n",
            "[200]\ttrain's rmse: 0.666326\tvalid's rmse: 0.718856\n",
            "[300]\ttrain's rmse: 0.630972\tvalid's rmse: 0.708329\n",
            "[400]\ttrain's rmse: 0.602375\tvalid's rmse: 0.701904\n",
            "[500]\ttrain's rmse: 0.577565\tvalid's rmse: 0.697407\n",
            "[600]\ttrain's rmse: 0.554983\tvalid's rmse: 0.694548\n",
            "[700]\ttrain's rmse: 0.534607\tvalid's rmse: 0.692053\n",
            "[800]\ttrain's rmse: 0.515769\tvalid's rmse: 0.690125\n",
            "[900]\ttrain's rmse: 0.497792\tvalid's rmse: 0.688351\n",
            "[1000]\ttrain's rmse: 0.480882\tvalid's rmse: 0.68705\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[985]\ttrain's rmse: 0.483245\tvalid's rmse: 0.687041\n",
            "Fold 3 done. Fold time: 2508.3s\n",
            "\n",
            "-- Fold 4/5 --\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "[100]\ttrain's rmse: 0.721521\tvalid's rmse: 0.731222\n",
            "[200]\ttrain's rmse: 0.668154\tvalid's rmse: 0.705606\n",
            "[300]\ttrain's rmse: 0.632818\tvalid's rmse: 0.695314\n",
            "[400]\ttrain's rmse: 0.604329\tvalid's rmse: 0.689854\n",
            "[500]\ttrain's rmse: 0.57935\tvalid's rmse: 0.685739\n",
            "[600]\ttrain's rmse: 0.556786\tvalid's rmse: 0.682622\n",
            "[700]\ttrain's rmse: 0.53583\tvalid's rmse: 0.680607\n",
            "[800]\ttrain's rmse: 0.517225\tvalid's rmse: 0.67851\n",
            "[900]\ttrain's rmse: 0.499194\tvalid's rmse: 0.676895\n",
            "[1000]\ttrain's rmse: 0.482601\tvalid's rmse: 0.675914\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttrain's rmse: 0.482601\tvalid's rmse: 0.675914\n",
            "Fold 4 done. Fold time: 2114.1s\n",
            "\n",
            "-- Fold 5/5 --\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "[100]\ttrain's rmse: 0.716833\tvalid's rmse: 0.751167\n",
            "[200]\ttrain's rmse: 0.663557\tvalid's rmse: 0.727195\n",
            "[300]\ttrain's rmse: 0.62838\tvalid's rmse: 0.717362\n",
            "[400]\ttrain's rmse: 0.599689\tvalid's rmse: 0.7118\n",
            "[500]\ttrain's rmse: 0.574815\tvalid's rmse: 0.70766\n",
            "[600]\ttrain's rmse: 0.552267\tvalid's rmse: 0.705079\n",
            "[700]\ttrain's rmse: 0.531583\tvalid's rmse: 0.702645\n",
            "[800]\ttrain's rmse: 0.512442\tvalid's rmse: 0.700657\n",
            "[900]\ttrain's rmse: 0.494435\tvalid's rmse: 0.699254\n",
            "[1000]\ttrain's rmse: 0.477713\tvalid's rmse: 0.698007\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[999]\ttrain's rmse: 0.477862\tvalid's rmse: 0.697993\n",
            "Fold 5 done. Fold time: 2133.7s\n",
            "Config 'fast' OOF SMAPE: 53.2082%\n",
            "\n",
            "=== Config 2/2: robust ===\n",
            "\n",
            "-- Fold 1/5 --\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "[100]\ttrain's rmse: 0.711248\tvalid's rmse: 0.762846\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2463642210.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m# Early stopping callback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# -----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         model = lgb.train(\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mlgb_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    320\u001b[0m             )\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_LGBM_BoosterEvalMethodResultType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   4153\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot update due to null objective function.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4154\u001b[0m             _safe_call(\n\u001b[0;32m-> 4155\u001b[0;31m                 _LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   4156\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4157\u001b[0m                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# Step 11b ‚Äì Mini Config 2 (3 folds x 600 rounds)\n",
        "# ================================================\n",
        "from sklearn.model_selection import KFold\n",
        "import lightgbm as lgb\n",
        "import numpy as np\n",
        "import gc\n",
        "import time\n",
        "\n",
        "# 3-fold CV, max 600 rounds\n",
        "MINI_N_FOLDS = 3\n",
        "MINI_MAX_ROUNDS = 600\n",
        "\n",
        "kf_mini = KFold(n_splits=MINI_N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "# mini Config 2\n",
        "mini_cfg = {\"name\":\"robust_mini\",\"num_leaves\":64,\"learning_rate\":0.03,\"n_jobs\":2}\n",
        "\n",
        "oof_preds_mini = np.zeros(len(train), dtype=np.float64)\n",
        "test_preds_mini = np.zeros(X_test.shape[0], dtype=np.float64)\n",
        "\n",
        "fold = 0\n",
        "t_total = time.time()\n",
        "for train_idx, valid_idx in kf_mini.split(X_train):\n",
        "    fold += 1\n",
        "    t_fold = time.time()\n",
        "    print(f\"\\n-- Mini Fold {fold}/{MINI_N_FOLDS} --\")\n",
        "\n",
        "    X_tr = X_train[train_idx]\n",
        "    X_val = X_train[valid_idx]\n",
        "    y_tr = y_log[train_idx]\n",
        "    y_val = y_log[valid_idx]\n",
        "\n",
        "    lgb_params = {\n",
        "        \"objective\": \"regression\",\n",
        "        \"metric\": \"rmse\",\n",
        "        \"boosting_type\": \"gbdt\",\n",
        "        \"learning_rate\": mini_cfg['learning_rate'],\n",
        "        \"num_leaves\": mini_cfg['num_leaves'],\n",
        "        \"max_depth\": -1,\n",
        "        \"feature_fraction\": 0.8,\n",
        "        \"bagging_fraction\": 0.9,\n",
        "        \"bagging_freq\": 1,\n",
        "        \"verbose\": -1,\n",
        "        \"seed\": RANDOM_STATE,\n",
        "        \"n_jobs\": mini_cfg['n_jobs']\n",
        "    }\n",
        "\n",
        "    dtrain = lgb.Dataset(X_tr, label=y_tr)\n",
        "    dvalid = lgb.Dataset(X_val, label=y_val)\n",
        "\n",
        "    model = lgb.train(\n",
        "        lgb_params,\n",
        "        dtrain,\n",
        "        num_boost_round=MINI_MAX_ROUNDS,\n",
        "        valid_sets=[dtrain, dvalid],\n",
        "        valid_names=['train','valid'],\n",
        "        verbose_eval=100\n",
        "    )\n",
        "\n",
        "    # Predict log1p space -> convert back\n",
        "    val_pred_log = model.predict(X_val, num_iteration=model.best_iteration)\n",
        "    oof_preds_mini[valid_idx] = np.expm1(val_pred_log)\n",
        "\n",
        "    test_pred_log = model.predict(X_test, num_iteration=model.best_iteration)\n",
        "    test_preds_mini += np.expm1(test_pred_log)\n",
        "\n",
        "    print(f\"Mini Fold {fold} done. Fold time: {time.time()-t_fold:.1f}s\")\n",
        "\n",
        "    # free memory\n",
        "    del X_tr, X_val, y_tr, y_val, dtrain, dvalid, model, val_pred_log, test_pred_log\n",
        "    gc.collect()\n",
        "\n",
        "# average test predictions over folds\n",
        "test_preds_mini /= MINI_N_FOLDS\n",
        "\n",
        "# combine with Config 1 predictions (already done)\n",
        "final_test_preds = (test_preds_all + test_preds_mini) / 2.0  # simple average ensemble\n",
        "\n",
        "# OOF SMAPE for mini Config 2\n",
        "def smape(y_true, y_pred):\n",
        "    y_true = np.array(y_true, dtype=np.float64)\n",
        "    y_pred = np.array(y_pred, dtype=np.float64)\n",
        "    denom = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
        "    denom[denom == 0] = 1e-8\n",
        "    return np.mean(np.abs(y_true - y_pred) / denom) * 100.0\n",
        "\n",
        "mini_oof_smape = smape(y, oof_preds_mini)\n",
        "final_oof_smape = smape(y, (oof_preds_all + oof_preds_mini)/2.0)\n",
        "print(f\"\\nMini Config 2 OOF SMAPE: {mini_oof_smape:.4f}%\")\n",
        "print(f\"Final ensemble OOF SMAPE: {final_oof_smape:.4f}%\")\n",
        "print(f\"Mini 3-fold training done in {time.time()-t_total:.1f}s (~{(time.time()-t_total)/60:.1f} min)\")\n"
      ],
      "metadata": {
        "id": "_CvnjOYt9u3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Step 12) Save artifacts safely (vectorizers + metadata)\n",
        "# =========================================================\n",
        "import joblib, os, gc\n",
        "\n",
        "t0 = time.time()\n",
        "print(\"\\n=== Step 12: Saving artifacts safely ===\")\n",
        "\n",
        "try:\n",
        "    # Create artifacts dictionary (no large models inside)\n",
        "    artifacts = {\n",
        "        \"tfidf_word\": tfidf_word,\n",
        "        \"tfidf_char\": tfidf_char,\n",
        "        \"num_feat_columns\": list(num_feat_train.columns),\n",
        "        \"img_feat_columns\": list(img_feat_train.columns),\n",
        "        \"lgb_configs\": LGB_CONFIGS,\n",
        "        \"final_oof_smape\": final_smape,\n",
        "        \"random_state\": RANDOM_STATE,\n",
        "        \"n_folds\": N_FOLDS\n",
        "    }\n",
        "\n",
        "    # Save using joblib (compressed for size efficiency)\n",
        "    joblib.dump(artifacts, ARTIFACTS_F, compress=3)\n",
        "\n",
        "    # Verification step\n",
        "    if os.path.exists(ARTIFACTS_F):\n",
        "        size_mb = os.path.getsize(ARTIFACTS_F) / (1024 * 1024)\n",
        "        print(f\"‚úÖ Artifacts saved successfully ‚Üí {ARTIFACTS_F} ({size_mb:.2f} MB)\")\n",
        "    else:\n",
        "        print(\"‚ö† Warning: Artifacts file not found after save attempt!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Error saving artifacts:\", str(e))\n",
        "    # Backup attempt\n",
        "    backup_path = ARTIFACTS_F.replace(\".joblib\", \"_backup.joblib\")\n",
        "    try:\n",
        "        joblib.dump(artifacts, backup_path, compress=1)\n",
        "        print(f\"üü° Saved backup artifacts to {backup_path}\")\n",
        "    except Exception as e2:\n",
        "        print(\"‚ùå Backup save also failed:\", str(e2))\n",
        "\n",
        "# Memory cleanup\n",
        "gc.collect()\n",
        "print(f\"Step 12 completed in {time.time() - t0:.2f}s\")\n",
        "print(\"Crash risk: ‚úÖ Very low (small dictionary, no large model objects).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmbnYsBf-szL",
        "outputId": "b89dd6ad-0648-42a3-eaff-2de09ead431d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Step 12: Saving artifacts safely ===\n",
            "‚ùå Error saving artifacts: name 'tfidf_word' is not defined\n",
            "‚ùå Backup save also failed: name 'artifacts' is not defined\n",
            "Step 12 completed in 1.97s\n",
            "Crash risk: ‚úÖ Very low (small dictionary, no large model objects).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Step 13) Create and save submission (no dependency on Step 12)\n",
        "# =========================================================\n",
        "import pandas as pd, numpy as np, os, time\n",
        "\n",
        "t0 = time.time()\n",
        "print(\"\\n=== Step 13: Creating and saving submission file (independent) ===\")\n",
        "\n",
        "try:\n",
        "    # --- Safety checks ---\n",
        "    if 'test' not in globals() or 'test_preds_all' not in globals():\n",
        "        raise RuntimeError(\"Required variables not found in memory: please ensure 'test' and 'test_preds_all' exist.\")\n",
        "\n",
        "    # --- Create submission DataFrame ---\n",
        "    submission = pd.DataFrame({\n",
        "        \"sample_id\": test['sample_id'].values,\n",
        "        \"price\": np.maximum(test_preds_all, 0.0)\n",
        "    })\n",
        "\n",
        "    # --- Save submission to CSV ---\n",
        "    submission.to_csv(\"test_out.csv\", index=False)\n",
        "\n",
        "    # --- Verify file saved ---\n",
        "    if os.path.exists(\"test_out.csv\"):\n",
        "        size_kb = os.path.getsize(\"test_out.csv\") / 1024\n",
        "        print(f\"‚úÖ Submission saved successfully ‚Üí test_out.csv  ({size_kb:.1f} KB)\")\n",
        "        print(f\"üìÑ Shape: {submission.shape}\")\n",
        "        print(\"\\nTop 5 rows preview:\")\n",
        "        display(submission.head())\n",
        "    else:\n",
        "        print(\"‚ö† Warning: CSV not found after saving attempt!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Submission creation failed:\", str(e))\n",
        "    # Try backup\n",
        "    try:\n",
        "        submission.to_csv(\"test_out_backup.csv\", index=False)\n",
        "        print(\"üü° Backup saved to test_out_backup.csv\")\n",
        "    except:\n",
        "        print(\"Backup save also failed.\")\n",
        "\n",
        "print(f\"Step 13 completed in {time.time()-t0:.2f}s\")\n",
        "print(\"üöÄ You can now upload 'test_out.csv' to the Amazon ML Challenge portal.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "jWYM8ujDApXu",
        "outputId": "8cd51e0a-b563-4ee8-fe4b-1af5757d204d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Step 13: Creating and saving submission file (independent) ===\n",
            "‚úÖ Submission saved successfully ‚Üí test_out.csv  (1835.5 KB)\n",
            "üìÑ Shape: (75000, 2)\n",
            "\n",
            "Top 5 rows preview:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   sample_id      price\n",
              "0     100179  15.800496\n",
              "1     245611  10.833378\n",
              "2     146263  25.940461\n",
              "3      95658  10.765281\n",
              "4      36806  33.907073"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef93e09c-e93f-4440-8824-dd207557641a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_id</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100179</td>\n",
              "      <td>15.800496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>245611</td>\n",
              "      <td>10.833378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>146263</td>\n",
              "      <td>25.940461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>95658</td>\n",
              "      <td>10.765281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36806</td>\n",
              "      <td>33.907073</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef93e09c-e93f-4440-8824-dd207557641a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ef93e09c-e93f-4440-8824-dd207557641a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ef93e09c-e93f-4440-8824-dd207557641a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d4495e45-68e9-4327-8e5e-6c82aab7d00f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d4495e45-68e9-4327-8e5e-6c82aab7d00f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d4495e45-68e9-4327-8e5e-6c82aab7d00f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\ud83d\\ude80 You can now upload 'test_out\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"sample_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 77868,\n        \"min\": 36806,\n        \"max\": 245611,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          245611,\n          36806,\n          146263\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.17499925566628,\n        \"min\": 10.765280723571777,\n        \"max\": 33.907073211669925,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          10.833378219604493,\n          33.907073211669925,\n          25.94046058654785\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 13 completed in 0.55s\n",
            "üöÄ You can now upload 'test_out.csv' to the Amazon ML Challenge portal.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def smape(y_true, y_pred):\n",
        "    y_true = np.array(y_true, dtype=np.float64)\n",
        "    y_pred = np.array(y_pred, dtype=np.float64)\n",
        "    denom = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
        "    denom[denom == 0] = 1e-8\n",
        "    return np.mean(np.abs(y_true - y_pred) / denom) * 100.0\n",
        "\n",
        "# Calculate\n",
        "final_smape_check = smape(y, oof_preds_all)\n",
        "print(f\"‚úÖ Final SMAPE on training (OOF): {final_smape_check:.4f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe4GjfxHBRNt",
        "outputId": "123bf3b6-981b-4c6c-9f63-3bb7a52a7d33"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Final SMAPE on training (OOF): 53.2082%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content | grep test_out.csv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIXcDlL7D5n8",
        "outputId": "c74fcc4f-065a-492e-ef40-5ad6190aa387"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 1.8M Oct 13 14:38 test_out.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/test_out.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "rc54GV0qEElD",
        "outputId": "17e9e5cc-ca5e-4c46-83c3-d1d5979e1d62"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_29255f07-e448-43ed-97d4-59c31e49a235\", \"test_out.csv\", 1879511)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def smape(y_true, y_pred):\n",
        "    y_true = np.array(y_true, dtype=np.float64)\n",
        "    y_pred = np.array(y_pred, dtype=np.float64)\n",
        "    denom = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
        "    denom[denom == 0] = 1e-8\n",
        "    return np.mean(np.abs(y_true - y_pred) / denom) * 100.0\n"
      ],
      "metadata": {
        "id": "1fOFwZHIFFjW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_smape = smape(y, oof_preds_all)\n",
        "print(\"Final OOF SMAPE:\", round(final_smape, 4), \"%\")\n",
        "print(\"Estimated accuracy:\", round(100 - final_smape, 2), \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOrooPrSFJA1",
        "outputId": "b1180461-2c26-460b-8af2-1603612ab69c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final OOF SMAPE: 53.2082 %\n",
            "Estimated accuracy: 46.79 %\n"
          ]
        }
      ]
    }
  ]
}